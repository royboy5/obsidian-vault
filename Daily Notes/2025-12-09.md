---
tags: daily-note
status: in-progress / processed
---

## ðŸ““ Daily Note: 2025-12-09


### Master Tasks
*What are the main things you want to accomplish today? (Often related to your active project)*
- [ ]
- [ ]
- [ ]

---

## ðŸ“¥ Inbox (Your "Messy" Capture Space)
*As you watch tutorials, read articles, or have ideas, capture them here. Don't worry about structure. This is your "fleeting notes" area for the day.*

- FEM - TS Monorepo
	- monorepo - many software packages being stored in the same SCM repo
		- A single git repository that contains multiple packages, where different parts of a software project can be organized and developed together
	- What is a key benefit of using a monorepo for dependency management?
		- In a monorepo, changes can be made across multiple packages in a single pull request without requiring additional steps like manually updating dependency versions in different repositories
	- How does a monorepo simplify testing across a project's dependency graph?
		- In a monorepo, it becomes easier to run the entire test suite for all dependent packages when a change is made, ensuring that modifications work correctly across the entire project
	- What problem does a monorepo help solve in large software ecosystems?
		- A monorepo helps prevent dependency updates from becoming complex and time-consuming, reducing the likelihood of packages being years behind on updates
	- What is an example of how companies might structure their monorepos?
		- Some companies create separate monorepos for different programming languages, such as having one monorepo for Java code, another for Ruby code, and a third for JavaScript code
	- Tools
		- pnpm
		- lerna
		- nx
		- api-extractor
		- api-documenter
		- changesets
		- etc
	- What is dependency aware task execution in a monorepo?
		- It allows running tests, linting, or other tasks only for packages that could be potentially affected by changes in a low-level dependency, including the touched package and anything that depends on it
	- What is the purpose of using API extractor and documenter in a monorepo?
		-To create a deliberately controlled API surface for each package, generate auto-generated documentation, create a single declaration file (DTS), and tag exported methods and fields with maturity levels like internal, alpha, or beta
	- What problem does Syncpack help solve in a monorepo?
		- Syncpack helps de-duplicate package versions across multiple packages in a monorepo, alerting and helping to consolidate different versions of the same package into a single consistent version
	- What does the library Knip help identify in a monorepo?
		- Knip helps identify needless exports from libraries that aren't being consumed within the monorepo, and unneeded dependencies in package.json files
	- What is a code owners file used for in a monorepo context?
		- A code owners file governs automatic PR reviews by specifying which team or individuals are responsible for reviewing code in specific packages or directories, with the ability to synchronize this information across individual packages and a root-level file
		- Q - Deeper dive into mono vs poly repos
	- What is the relationship between mono repos and micro front-end architecture?
		- Micro front-ends are often arranged as packages within a monorepo, allowing for distinct subparts of a UI to be composed together with strong encapsulation and well-defined contracts between components.
	- What are the benefits of using cached build steps in development tools like Turbo Repo and NX?
		- Cached build steps allow skipping tasks with unchanged inputs, preserving the same output across development teams and CI jobs. This approach can significantly speed up build processes by avoiding redundant work when inputs haven't changed.
	- What are key considerations when deciding between a monorepo and a poly repo?
		- Key considerations include the interrelatedness of packages, the complexity of tooling and conventions that need to be enforced, and the potential pain of keeping multiple repositories upgraded. Small, self-contained projects might not benefit from a monorepo approach.
	- What type of project structure might benefit from a monorepo approach?
		- Projects with highly interconnected packages, such as Babel with its core, plugins, and CLI, or companies with sophisticated tooling and upgrade management needs, are good candidates for a monorepo structure.
	- What are two main concepts in tools like Turbo Repo and NX?
		- The two main concepts are: 1) Cached build steps, where tasks with consistent inputs and outputs can be skipped, and 2) A cloud service that allows sharing these cached results across development teams and CI environments.
	- Setup
		- root level should have things like
			- .gitignore
			- .nvpmrc
			- .prettierrc
			- pnpm-lock.yaml
			- README.md
		- Create `pnpm-workspace.yaml` on root
			-  ```yaml
			  packages:
				  - 'packages/*'
			  ```
		  - thin `package.json`
			  - ```js
			    {
					"scripts": {
						"build": "pnpm --color run -r build",
						"lint": "pnpm --color run -r lint",
						"check": "pnpm --color run -r check",
						"test": "pnpm --color run -r test",
						"format": "pnpm --color run -r format",
						"dev": "pnpm --color run -r dev"
					},
					"volta": {
						"node": "22.16.0"
					}
				}
			    ```
				- scripts should be the same across all packages
		- What is the purpose of using an NPM scope in a monorepo?
			- An NPM scope indicates that packages are interrelated and can be published together under a common prefix, providing a way to organize and identify packages from the same project or organization in the package registry. (i.e @seeds/ui - @seeds is the scope)
		- What does theÂ `private: true`Â setting in a package.json file do?
			- TheÂ `private: true`Â setting prevents the package manager from publishing the package to NPM, effectively keeping the package for internal use only.
		- What command does PNPM use to run build tasks across multiple packages in a workspace?
			- PNPM usesÂ `pnpm run -r build`Â to recursively run build tasks across all packages defined in the workspace YAML file.
		- What is the benefit of preserving a rename in Git compared to a deletion and addition?
			- Preserving a rename maintains the git history of the file, preventing loss of the file's previous context and keeping the git blame intact.
		- What is the purpose of the pnpm-workspace.yaml file?
			- The pnpm-workspace.yaml file tells PNPM where to look for subfolders that represent packages in a monorepo, typically by specifying the packages directory.
		- What is the recommended starting point for refactoring a project?
			- Start with the lowest level modules that many things depend on, but which do not depend on much else. In this case, the Models package is a good candidate because it has minimal dependencies.
		- What is the purpose of creating anÂ `index.ts`Â file in a package?
			- TheÂ `index.ts`Â file serves as a deliberate entry point for the library, allowing controlled exports and creating a curated public API surface. It helps manage what symbols and modules are exposed to users of the library.
		- What does PNPM do differently compared to NPM in managing dependencies in a monorepo?
			- PNPM creates a flat, symbolic-linked structure for dependencies across packages, where dependencies are centrally stored and referenced, unlike NPM which creates nested node_modules folders for each package.
		- Why is theÂ `preserve`Â flag useful when using TypeScript's watch mode?
			- TheÂ `preserve`Â flag prevents clearing the console output between compilations, allowing developers to see previous type checking errors and maintain context while making code changes.
		- What are the two main TypeScript configuration files typically created for a package?
			- tsconfig.json (for authoring feedback) and tsconfig.build.json (for compilation)
		- What two package.json fields specify the entry points for a TypeScript library?
			- types (for type definitions) and module (for runnable code)
		- How can TypeScript configuration files be structured in a monorepo to maintain consistent settings?
			- By using a base tsconfig.json in the root, which is extended by package-specific tsconfig files, allowing for shared strictness settings and conventions
		- What is the purpose of specifying 'types' and 'module' fields in a package.json file?
			- They specify the entry points for type checking and runtime code execution, helping resolve where specific JavaScript files or type definition files can be found within a package
		- What is a PNPM workspace dependency specifier, and how does it work?
			- A PNPM workspace dependency specifier allows referencing a local package within a monorepo, with the resolution algorithm first checking if the dependency can be met within the local workspace before looking elsewhere
		- Why is importing types using theÂ `type`Â keyword beneficial during build processes?
			- Importing types with theÂ `type`Â keyword helps with tree shaking by allowing build tools to eliminate unused dependencies during production builds, as these imports are only used for type information and do not exist at runtime
		- What performance challenges can TypeScript language servers experience in large monorepos?
			- TypeScript language servers can face significant performance issues in large monorepos, including slow type checking, high memory consumption, and computational overhead, which may require strategies like project references to mitigate
		- What is the relationship between package dependencies in a PNPM monorepo build process?
			- PNPM understands inter-package dependencies and will automatically build dependent packages in the correct order, ensuring that dependencies like models are compiled before packages that depend on them
		- What is the purpose of enabling the project service in ESLint configuration?
			- To enable type-aware linting rules that require type information, which involves pointing to a tsconfig file or tsconfig root directory
		- What doesÂ `declaration map true`Â do in a TypeScript configuration?
			- It generates source maps for declaration files, enabling 'jump to definition' functionality and allowing developers to navigate directly to the original TypeScript source code
		- Why is having a single ESLint configuration at the root of a monorepo beneficial?
			- It is more efficient, especially as the number of packages grows, and provides a centralized location for linting rules across the entire project
		- What happens if a TypeScript file is not included in a tsconfig or not type-checked?
			- ESLint cannot properly lint the file because it cannot generate the Abstract Syntax Tree (AST) and type information necessary for type-aware linting rules
		- What is an advantage of keeping source code in an NPM published library?
			- It allows developers to create patches, understand the implementation, and make temporary modifications to dependencies without forking the entire library
				- Q - look into git patch?
		- What does the Knip tool help identify in a JavaScript project?
			- Knip helps identify unused exports from modules and dependencies that are not being imported within a monorepo or project
		- How does Knip differ from traditional tree shaking?
			- Knip identifies unused dependencies and exports at a project level, while tree shaking eliminates unused code during the build process at a module level
		- Why is it important to be deliberate about code exports?
			- Being deliberate about exports helps prevent external users from accessing internal implementation details, making it easier to evolve code and maintain a clean API surface
		- What configuration fields are typically needed in a Knip configuration file?
			- A Knip configuration file typically requires workspace locations, entry points, source code patterns, and potentially an ignore dependencies list
		- What are the two primary benefits of using Knip in a project?
			- Knip helps eliminate unused dependencies and dev dependencies, and ensures that code exports are intentional and deliberate
		- What command does PNPM use to run a script on a specific package?
			- PNPM filter, which allows running a script on a single package in a monorepo
		- What is the purpose of the 'concurrently' npm package?
			- To run multiple commands concurrently and provide color-coded output for each task
		- What is the benefit of having a dev script with immediate feedback?
			- Developers can see code changes take effect immediately without a lengthy compile step, creating a quick feedback loop
		- What does PNPM DLX do?
			- Similar to NPX, it allows downloading and executing a package on the fly without permanently installing it
		- Why is color coding important when running multiple tasks concurrently?
			- Color coding helps distinguish between different task outputs, making it easier to identify which output comes from which task
		- What is the purpose of settingÂ `composite true`Â in a TypeScript configuration file?
			- It enables a package to be compiled in a way where its build information can be stitched together with other pieces of build information, allowing for more incremental rebuilds at the module level.
		- What is the recommended practice when establishing project references in a TypeScript monorepo?
			- If you have a workspace dependency, you should also establish a corresponding project reference to enable performance improvements and incremental compilation.
		- What is the significance of project references in terms of build performance?
			- Project references allow for more granular incremental compilation at the module level, reducing rebuild time by preserving and reusing previously compiled artifacts, especially in large monorepos.
		- How do project references differ from traditional package imports?
			- Project references provide instructions for compile-time module resolution and enable more efficient incremental builds, beyond just pointing to a dist folder or import location.
		- What type of files should be added toÂ `.gitignore`Â when working with TypeScript project references?
			- The build info files (typically withÂ `.tsbuildinfo`Â extension) should be ignored in Git, as they are generated files meant for programs to understand and will change frequently.
		- What are the two main purposes of API Extractor?
			- API Extractor analyzes declaration files in build output and creates a rollup of those declaration files, generating a single DTS file containing all potentially exported types and creating an API report in markdown format
		- What do the different trimmed file paths (untrimmed, alpha, beta, public) represent in API Extractor?
			- They represent increasing levels of API maturity and stability, with untrimmed being the least mature and public being the most stable. These paths allow developers to progressively expose and refine API surfaces using JSDOC tags
		- What is the purpose of theÂ `ae-missing-release-tag`Â configuration in API Extractor?
			- TheÂ `ae-missing-release-tag`Â rule warns developers when they export types or functions without specifying their release status (public, beta, alpha, or internal), encouraging more explicit API documentation
		- How can API Extractor help with type exports in a monorepo?
			- API Extractor allows developers to have fine-grained control over type visibility across packages, enabling selective type exposure for testing or inter-package communication without fully publicizing an API surface
		- What additional type-related check can API Extractor perform?
			- API Extractor can ensure that when a function or class is exported, the types used in its signature (argument and return types) are also directly exported, making type annotations easier to create and understand
		- What is the purpose of the API report?
			- The API report is a markdown file that shows exactly what is being exported from a module, encodes warnings, and helps developers review code changes by clearly displaying the exposed API surface of a library
		- How can an API report help during a pull request review?
			- It makes it clear whether code changes have ripple effects that downstream users will experience, and helps identify if changes are breaking or non-breaking to the library's API
		- What is the benefit of creating an API report in a build process?
			- It allows developers to easily spot API surface changes, understand potential impacts on library users, and potentially integrate with bots to automatically review and highlight API modifications
		- What file is mentioned alongside the API report that might be used for future documentation?
			- Models API JSON, which is suggested as a potential source for generating API documentation
		- In what format is the API report generated?
			- The API report is generated as a markdown file, which renders nicely on GitHub and provides a clear view of the module's exported components
		- What command is used to generate markdown documentation with API Documenter?
			- pnpm api-documenter markdown -i temp -o docs
		- What type of documentation can API Documenter generate besides markdown?
			- YAML file, which can be fed into documentation systems like Docusaurus
		- What are the primary sources of information for API Documenter's generated documentation?
			- Code comments and type information
		- What is a benefit of using API Documenter for generating documentation?
			- It creates a browsable, multi-page documentation structure that can be tracked over time through version control
		- What folder is typically used as input for API Documenter?
			- A temporary folder (in this example, 'temp') containing API Extractor output
		- What does the commandÂ `pnpm lerna run build`Â do in a monorepo?
			- It runs the build task across all packages in the workspace, building each package using Nx as the underlying task runner
		- What does theÂ `--stream`Â flag do when running Lerna tasks?
			- It displays the full output of tasks in real-time, instead of just showing completion status, allowing you to see detailed build, lint, and test outputs
		- How can you control the number of parallel tasks in Lerna?
			- By using theÂ `--concurrency`Â flag, you can specify how many tasks can run simultaneously. For example,Â `--concurrency 2`Â limits parallel execution to two tasks at a time
		- What does theÂ `--scope`Â flag do in Lerna task running?
			- TheÂ `--scope`Â flag allows you to run tasks only on specific packages, such as running tasks only in a package likeÂ `seeds/ui`Â by usingÂ `pnpm lerna run build --scope seeds/ui`
		- How does Lerna handle task artifacts and caching?
			- Nx, which powers Lerna, caches task artifacts and detects changes in inputs to determine if a task needs to be re-run, identifying potentially 'flaky' tasks based on input variations
		- What command allows running tasks on a subset of packages based on changes in a monorepo?
			- pnpm lerna run [task] --since=[git-ref], which identifies changes and runs tasks on affected packages and their downstream dependencies
		- What is the key benefit of using a build tool aware of the dependency graph in a monorepo?
			- It allows running tests, linting, or builds only on packages that have changed or are downstream from changed packages, reducing computational overhead
		- How does theÂ `--since`Â flag help optimize testing and building in a monorepo?
			- It allows running tasks on only the packages that have been modified and their downstream dependencies, avoiding running tests or builds on the entire project
		- Why does the dependency graph approach become more valuable as a project grows?
			- As a project becomes larger, the computational cost of running full builds, tests, and lints increases, making incremental and targeted task running more efficient
		- What problem does the monorepo tooling solve compared to a traditional single repository setup?
			- It prevents the need to run entire test suites for all packages when only a small change is made, while maintaining the ability to validate downstream impacts
		- What command is used to globally install nx?
			- You can use 'npm install -g nx', 'volta install nx', or 'pnpm install -g nx'
		- What command initializes nx in a project?
			- pnpm nx init
		- What does 'cacheable' mean in the context of nx tasks?
			- A task is cacheable if it produces the same output given the same input, such as build, lint, and test tasks
		- What is the primary benefit of nx's remote caching?
			- If someone builds something with identical inputs on another machine, you can benefit from their pre-existing build result without rebuilding
		- What types of tasks are typically considered cacheable in nx?
			- Build, lint, test, and format tasks are usually considered cacheable because they produce consistent outputs for the same inputs
		- What command does Nx use to run the build target for every project in a workspace?
			- pnpm nx run-many -t build
		- What is the primary advantage of using Nx over PNPM for task running in a monorepo?
			- Nx provides sophisticated task orchestration, including understanding interdependencies between tasks, git diff awareness, and the ability to run only relevant tasks based on changes
		- What does theÂ `target defaults`Â configuration inÂ `nx.json`Â allow developers to do?
			- It allows developers to define default task configurations for the entire monorepo, reducing the need for individual package-specific task scripts and centralizing task definitions
		- How can Nx help manage task dependencies in a monorepo?
			- Nx allows setting up task dependencies, such as running build before test, or running prettier before linting, providing more control over task execution order
		- What is the relationship between Nx and a package manager like PNPM?
			- Nx does not replace the package manager but complements it by providing advanced task running, caching, and dependency graph management capabilities
		- 
---

### Meeting Notes
*Create a quick heading for any meetings you have.*

#### Meeting: [Project / Topic Name]
* **Attendees: **
* **Notes:**
* **Action Items:**
	- [ ] @[Person] - ...

---

## Open Questions
*Quickly capture questions as they arise.  These can be processed into full "Q - " notes later.*

* q: ...
* q: ...

---

### End of Day Review
*A quick checklist to process your day*

- [ ] **Process Messy Notes:** Move all items from "Messy Notes Inbox" into their proper folders
- [ ] **Process Questions:** Convert any "q:" items into full `Q - ...` notes
- [ ] **Review Tasks:** Migrate any unfinished tasks to tomorrow's daily noes or back to your project hub.
- [ ] 